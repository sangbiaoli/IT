##分布式服务架构

1. 垂直应用框架面临的挑战

    1. 复杂应用的开发和维护成本变高，部署效率逐渐降低。

    2. 团队协作效率差，部分公共功能重复开发代码重复率居高不下。

    3. 系统可靠性变差。随着业务的发展，访问量逐渐攀升。网络流量负载均衡，数据库连接等面临巨大的压力。某个节点的故障会导致分摊到其他节点的流量都增。引起雪崩效应高并发，大流量对系统的可要求非常高。

    4. 维护和定制困难。随着业务代码不断膨胀，功能越来越复杂。有的垂直架构模式已经无法应付，大的业务进行拆分代码修改，牵一发而动全身，维护和盯着都非常麻烦。

    5. 新功能上线周期变长。

2. RPC框架

    RPC框架的目的就是让远程过程调用变得更加简单,透明。rpc框架负责屏蔽底层的传输方式，序列化方式和通信细节。

    在高并发，大流量的应用场景中，需要做集群，通常的组网方案是前端通过F5等负载均衡器做七层负载均衡（或者使用SLB等软负载），后端做对等集群部署。

    RPC的全程是remote procedure call.它是一种通信方式。允许像调用本地服务一样调用远程服务，它的具体实现方式可以不同，例如spring的http innoker,facebook的thrift二进制似有协议通信。

    PRC框架的目标就是让远程过程（服务）调用更加简单，透明，PRC框架负责屏蔽底层的传输方式（TCP/UDP）,序列化方式（XML/JSON/二进制）和通信细节。

3. PRC框架的核心技术点

    1. 远程服务提供者需要以某种形式提供服务调用相关的信息，包括但不限于服务接口定义，数据结构，或者中间态的服务定义文件。例如Thrift的IDL文件，WS-RPC的WSDL文件定义，甚至也可以是服务端的接口说明文档；服务调用者需要通过一定的途径获取远程服务调用相关信息例如服务端接口定义jar包导入，获取服务端IDL文件等。

    2. 远程代理对象：服务调用者调用的服务实际是远程服务的本地代理，对于java语言，它的实践就是JDK的动态代理，通过动态代理的拦截机制，将本地调用封装成远程服务调用。

    3. 通信：RPC框架与具体的协议无关，例如spring的远程调用支持http invoke,RMI invoke,MessagePack使用的是私有的二进制压缩协议。

    4. 序列化：远程通信，需要将对象转换成二进制码流进行网络传输，不同的序列化框架，支持的数据类型，数据包报销，异常类型和性能都不同。不同的PRC框架应用场景不同。

4. 简单的PRC框架实现：

    java原生序列化，socket通信，动态代理和反射机制，实现最简单的RPC框架。

    1. 服务提供者，它运行在服务端，负责提供服务接口定义和服务实现类。

    2. 服务发布者，它运行在RPC服务端，负责将本地服务发布成远程服务，供其他消费者调用。

    3. 本地服务代理，它运行在RPC客户端，通过代理调用远程服务提供者，然后将结果进行封装返回给本地消费者。


5. 业界主流RPC框架：


    * 由Facebook开发的远程服务调用框架**Apacke Thrift**
    * Hadoop的子项目**Avro-PRC**
    * caucho提供的基于binary-RPC实现的远程通信框架**Hession**
    * google开源的基于http/2和protobuf的通信RPC框架**gRPC**

    1. Apacke Thrift

        1. Apacke Thrift的特点

            * 跨语言

                Apacke Thrift是Facebook实现的一种高效的，支持多种编程语言的远程服务调用框架，它采用接口描述语言（IDL）定义并创建服务，支持可扩展的跨语言服务开发。所包含的代码生成引擎可以在多种语言中创建高效无缝的服务，如C++,java,python,php,ruby,erlang,perl,c#,cocoa,smalltack等。

            * 体积

                其传输数据采用二进制格式，相对XML和json等序列化方式体积更小，对于高并发，大数据量和多语言的环境更有优势。

            * 模式

                Apacke Thrift服务包含用于绑定协议和传输层的基础架构，它提供阻塞，非阻塞，单线程和多线程的模式运行在服务器上，可以和现有的J2EE服务器/web容器无缝对接。

        2. Apacke Thrift支持的数据类型

            * 基本类型：bool,byte,i16,i32,i64,double,string
            * 结构体类型：struct(javapojo对象)
            * 容器类型：list,set,map
            * 异常类型：exception，它可以满足各种语言复杂数据结构的传输

        3. Apacke Thrift支持的协议

            Thrift允许开发者选择客户端和服务端之间通信协议的类型，在传输协议上总体可以划分未文本和二进制传输协议。为节约带宽，提高传输效率，一共情况下使用二进制传输协议。在性能要求不高的场合，为了提高可读性有时也可以使用文本类型的协议。

        4. Apacke Thrift支持的通信方式

            通信方式|说明
            --|--
            TSocket|使用阻塞式I/O进行传输，最简单常用的模式
            TFramedTransport|使用非阻塞方式，按块的大小进行传输，类似Java中的NIO非阻塞通信
            TNonblockingTransport|使用非阻塞方式，用于构建异步客户端

    2. ApacheAvro

        ApacheAvro是hadoop下的一个子项目，它本身既是一个序列化框架，同时也实现了RPC的功能。

        1. 特性
            1. 丰富的数据结构类型
            2. 快速可压缩的二进制数据形式
            3. 存储持久数据的文件容器
            4. 提供远程过程调用PRC
            5. 简单的动态语言结合功能

        2. 特点

            特点|说明
            --|--
            支持动态模式|avro不需要生成代码，这有利于搭建通用的数据处理系统，同时避免了对业务代码的侵入
            数据无需加标签|读取数据前，avro能获取模式定义，avro在数据编码时只需要保留更少的类型信息，有利于减少序列化后的数据大小。
            无需手工分配的域标识|Thrift和protocol buffers使用一个用户添加的整型域唯一性定义一个字段，而avro则直接使用域名，该方法更加直观，更加易扩展。

        3. 可定制性

            1. 传输层和业务逻辑层分离，用户可以专注于业务逻辑开发；

            2. 服务端有一个协议注册工厂和序列化注册工厂，针对不同的应用场景用户可以定制私有协议和不同的序列化方式，满足业务领域服务的需求。客户端支持同步和异步调用，用户可以根据实际业务场景做不同的选择。

    3. Hessian

        1. 介绍

            Hessian是一个轻量级的二进制PRC框架，它通过Servlet提供远程服务，可以将某个请求映射到hessian服务。

            Spring的DispatcherServlet支持该功能，DispatcherServlet可将匹配模式的请求转发到hessian服务。hessian的server端提供一个servlet基类，用来处理发送的请求，而hessian的远程过程调用则使用动态代理来实现，采用面向接口编程。因此，hessian服务通常通过Java接口对外暴露。

        2. 优点

            1. 简单易用，面向接口编程，通过接口暴露服务，轻量级，可以穿透防火墙；
            2. 采用二进制传输，序列化效率高；
            3. 支持多语言，概括：Java，python，c++,.net,c#,php,ruby等
            4. 可以与spring集成，配置比较简单。

    4. gPRC

        1. 介绍

            gPRC是一个高性能，通用的开源PRC框架，主要面向移动应用开发并基于HTTP/2协议标准而设计，基于protobuf(protocolbuffers)序列化协议开发，支持众多开发语言。

            gprc基于http/2标准设计，带来诸如双向流，流控，头部压缩，单TCP连接上的多复用请求等特性。这些特性使得其在移动设备上表现更好，更省电和节省空间占用。

        2. 语言版本

            gPRC目前提供C,JAVA,GO语言版本，全部托管在GitHub上，分别是gPRC，gPRC-Java，gPRC-go.

        3. 主要特性

            1. **支持protobuf**: gPRC使用protobuf的IDL来定义数据结构和服务。protobuf是一个灵活，高效，结构化的数据序列化框架，相比于XML等传统的序列化工具，它更小，更快，更简单。protobuf支持数据结构化一次可以到处使用，设置跨语言使用，通过代码生成工具可以自动生成不同语言版本的源代码，甚至可以在使用不同版本的数据结构进程间进行数据传递，实现数据结构的前向兼容。当前gPRC仅支持protobuf，且不支持在浏览器中使用。由于gPRC的设计能够支持多种数据格式，所以读者能够很容易实现对其他数据格式（XML,JSON）的支持。

            2. **支持多种语言**：gPRC支持多种语言，并能够根据语言类型自动生成客户端和服务端代码，gPRC-Java已经支持Android开发。

            3. **支持http/2设计**：由于gPRC基于http/2标准设计，所以相对于其他rpc框架，gPRC带来了更多强大的功能，如双向流，头部压缩，多复用请求等，这些功能给移动设备带来重大好处，比如节省贷款，降低TCP连接次数，节省CPU使用和延长电池寿命等。同时，gPRC还能够提高了云端服务和web应用的性能，gPRC即能够在客户端应用，也能够在服务端应用，从而以透明的方式实现客户端和服务端的通信和简化通信系统的构建。

6. RPC框架面临的挑战

    1. 在大规模服务化之前，应用可能只是通过PRC框架简单的暴露和引用远程服务，通过配置服务端的URL地址进行远程服务调用，路由则通过F5硬件负载均衡器火SLB进行简单的负载均衡。当服务越来越多时，服务URL配置管理变得非常困难，F5硬件负载均衡器压力变大。此时需要一个服务注册中心，动态的注册和发现服务，使服务的位置透明，消费者在恩地缓存服务提供者列表，实现软负载均衡。

    2. 随着业务量的增加，业务的发展，服务间依赖关系变得复杂，甚至分不清哪个应用要在哪个应用之前启动，所以，此时，需要一个分布式消息跟踪系统可视化展示服务调用链，用于依赖分析，业务调用路径梳理等，防止业务架构腐朽化。

7. 服务

    1. SOA服务化架构

        SOA是一种粗粒度，松耦合的以服务为中心的架构，接口之间通过定义明确的协议和接口进行通信。   
        
        SOA特点

        1. SOA帮助人们站在一个新的高度理解企业级架构中各种组件的开发和部署形式
        2. 它可以帮助企业系统架构师更迅速，可靠，可重用的形式规划整个业务系统。相比传统的非服务化架构，SOA能够更加从容的应对复杂企业系统集成和需求的快速变化。

    2. 面向服务设计的原则

        1. 服务可用性：不管是否存在即时复用的机会，服务均被设计为潜在的可复用。

        2. 服务共享一个标准契约：为了服务提供者交互，消费者需要导入服务提供者的服务契约，这个契约可以是一个IDL文件，Java接口定义，WSDL文件，甚至是个接口说明文档。

        3. 服务是松耦合的：服务被设计为功能相对独立，尽量不依赖其他服务的独立功能提供者。

        4. 服务是底层逻辑的抽象：只有经服务契约所暴露的服务对外部世界可见，契约之外底层的实现逻辑是不可见的。

        5. 服务是可组合，可编排的：多个服务可能被编排组合成一个新的服务，者允许不同逻辑抽象的自由组合，促进服务的复用。

        6. 服务是自治的：逻辑由服务所控制，并位于一个清晰的边界内，服务已经在边界内被控制，不依赖于其他服务。

        7. 服务是无状态的：服务应当不需要管理状态信息，因此能够维持松耦合。服务应当被尽可能设计成无状态。

        8. 服务是可被自动发现的：服务发布上线后，允许被其他消费者自动发现；当服务提供者下线后，允许消费者接收服务下线通知。

    3. 服务治理挑战

        SOA服务化之后，业务的发展，服务数量的增多，运维带来的挑战：

        1. 分布式框架下的服务调用性能

        2. 服务化架构如何支持线性扩展

        3. 如何实现高效，实时的服务多维度监控

        4. 大规模分布式环境下的故障快速定界和定位

        5. 分布式环境下海量日志在线检索，模糊查询

        6. 服务的流控，超时控制，服务升降级等管控手段

        7. 服务的划分原则，如何实现最大程度复用

    4. SOA服务治理主要包括：

        1. 服务定义

        2. 服务生命周期管理

        3. 服务版本治理

        4. 服务注册中心

        5. 服务监控

        6. 运行期服务质量保障

        7. 快速的故障定界定位手段

        8. 服务安全

8. 微服务架构
    
    微服务架构是一种服务化架构风格，通过将功能分散到各个离散的服务中以实现对解决方案的解耦。

    1. 主要特征

        1. 原子服务，专注于做一件事：功能单一，依赖小，内聚性强。

        2. 高密度部署：重要的服务可以独立进程部署，非核心服务可以独立打包，合设到同一个进程中，服务被高密度部署。一台服务器上可以部署多个服务实例进程；如果是云端部署，则可以利用docker实现容器级部署，以降低部署成本，提升资源利用率。

        3. 敏捷交付：服务由小团队设计，开发，测试，部署，线上治理，灰度发布和下线，运维整个生命周期支撑，实现真正的devops

        4. 微自治：服务足够小，功能单一，可以独立打包，部署，升级，回滚，弹性收缩，不依赖其他服务，实现局部自治。

    2. 微服务对比SOA

        项目|SOA|微服务
        --|--|--
        1.服务拆分粒度|SOA首先要解决的是异构应用的服务化；|微服务强调的是服务拆分尽可能小，最好是独立的原子服务
        2.服务依赖|传统的SOA服务，有哦与需要重用已有的资产，存在大量的服务间依赖|微服务的设计理念是服务自治，功能单一独立，避免依赖其他服务产生耦合，耦合会带来更高的复杂度
        3.服务规模|传统的SOA服务粒度比较大，多数会采用将多个服务合并打包为war,因此服务实例数有限|微服务强调尽可能拆分，同时很多服务会独立部署，导致服务规模急剧膨胀，对服务治理和运维带来挑战 
        4.架构差异||微服务化之后，服务数量的激增会引起架构质量属性的变化
        5.服务治理|传统基于SOA的静态治理转变为服务运行态微治理，实时生效
        6.敏捷交付||服务由小团队设计，开发，设计，部署，治理，发布等。

《第二章：分布式服务框架入门》

在一个不断发展的大型应用中，新的业务需求和功能不断增加，技术也在不断演进，不同团队构建的功能子系统采用的技术也不同，子系统之间的开发，部署和运维模式也不同。

应用从集中式走向分布式：随着业务的发展，应用功能越来越多，打包，部署和新特性上线周期也越久，大流量，高并发的用户访问对后台服务的压力越来越大，我们只能通过不断增加硬件的方法来满足应用的低延时和高吞吐量。

1.业务不断发展

2.代码复用难题

3.敏捷交付

4.纵向拆分

5.横向拆分

服务治理的主要诉求：

1.生命周期管理

2.服务容量规划

3.运行期治理

4.服务安全

dubbo的工作原理:

1.轻量级Java容器通过main函数初始化spring上下文，根据服务提供者配置的XML将服务按照指定的协议发布，完成服务的初始化工作。

2.服务提供者根据配置的服务注册中心地址连接服务注册中心，将服务提供者信息发布到富足注册中心

3.消费者根据服务消费者XML配置文件的服务引用信息，连接到注册中心，获取指定服务的地址等路由锡尼希

4.服务注册中心根据服务订阅关系，动态的指定消费者推送服务地址信息

5.消费者调用远程服务时，根据路由策略，从本地缓存的服务提供者地址列表中选择一个服务提供者，然后根据协议类型建立链路，跨进程调用服务提供者。

Dubbo架构的主要质量属性：

1.连通性2.健壮性3.伸缩性4.扩展性

连通性：

1.注册中心负责服务地址的注册和查找，相当于目录服务，服务提供者和消费者只在启动时与注册中心交互，注册中心不转发请求，压力较小

2.监控中心负责统计各服务调用次数，调用时间等，统计先在内存中汇总后每分钟一次发送到监控中心服务器，并以报表展示。

3.服务消费者向注册中心获取服务提供者地址列表，并根据负载算法直接调用提供者，同事汇报调用时间到监控中心。

4.注册中心，服务提供者，服务消费者三者之间均为长连接，监控中心除外。

5.注册中心通过长连接感知服务提供者的存在，服务提供者宕机，注册中心将理解推送事件通知消费者

6.注册中心和监控中心全部宕机，不影响已运行的提供者和消费者，消费者在本地缓存了提供者列表。

7.注册中心和监控中心都是可以选择的，服务提供者可以直连服务提供者。

健壮性：

1.监控中心宕机不影响使用，只是丢失部分采样数据

2.数据库宕机，注册中心仍通过缓存提供服务列表查询，但不能注册新服务。

3.注册中心对等集群，任意一台宕机，将自动切换到另一台。

4.注册中心全部宕机，服务提供者和消费者仍能通过本地缓存通信。

5.服务提供者无状态，任意一台宕机，不影响使用

6.服务提供者全部宕机，服务消费者应用将无法使用，并无限次重连等待服务提供者回复。

伸缩性：

1.注册中心对等集群，可动态增加机器部署实例，所有客户端将自动发现新的注册中心。

2.服务提供者无状态，可动态增加机器部署实例，注册中心将推送新的服务提供者信息给消费者。

扩展性：

1.微内核+插件式设计，平等对待第三方：由插件管理容器构成微内核，其他外围功能都通过插件的方式实现，平等对待第三方，使用者可以替换平台的默认实现，也可以通过插件扩展新的功能。

2.管道式设计，服务调用前后提供拦截面：同故宫服务调用前拦截，事后通知的方式，开放服务调用拦截面给框架使用者，用于功能扩展，Dubbo自身的大多数功能，也基于Filter拦截实现。

3.原子化扩展点，最大化复用和扩展：扩展点是单个功能的抽象，只负责完成一件事，例如序列化框架扩展点，用于扩展dubbo默认提供的序列化方式。

淘宝的HSF：hsf是淘宝的分布式服务框架，框架功能如下：

1.配置化开发，对业务代码低侵入：支持通过springxml配置方式发布和消费服务，降低对业务代码的侵入。

2.插件管理体系：平台与应用分开部署，运行期依赖，外部采用与应用独立的classloader隔离，内部采用OSGi隔离。

3.异步NIO通信，多种序列化方式：通信框架使用基于Mina封装的TB-Remoting,序列化支持Java序列化，hessian等，服务提供者和消费者之间采用长连接进行通信。

4.灵活的路由能力：客户端软负载，随机，轮询等多种路由策略，支持容灾，失效回复等。

5.多协议支持：webservice,pb（protocolbuffer）,hession(Http)等。

6.服务治理：HSF支持多各维度的服务治理策略，包括服务监控，服务分组，限流降级，服务授权等。

亚马逊：Coralservice是亚马逊内部使用的基于Java的分布式服务框架，他的功能如下：

1.支持多协议

2.轻量级框架，非常容易与已有的系统继承。

3.配置化开发，对业务代码侵入低，开发效率高

4.与亚马逊的其他基础设施继承，实现DevOps。

分布式服务框架设计：

RPC层:包括底层通信框架（NIO框架的封装，共有协议的封装），序列化和反序列化框架，用于屏蔽底层通信协议细节和序列化方式差异的Remoting框架。

Filterchain层：服务调用职责链，提供多种服务调用切面供框架自身和使用者扩展，例如负载均衡，服务调用性能统计，服务调用完成通知机制，失败重发等。

Service层：主要包括Java动态代理，消费者使用，主要用于将服务提供者的接口封装成远程服务调用；Java反射，服务提供者使用，根据消费者请求消息中的接口名，方法名，参数列表反射调用服务提供者的接口本地实现类。再向上就是业务的服务接口定义和实现类，对于使用spring配置化开发的就是springbean，服务由雨雾来实现，平台负责将业务接口发布成远程服务。

《第三章：通信框架》

绝大多数的人不是服务框架（RPC）都推荐使用长连接进行内部通信，原因如下：

1.相比于短链接，长连接更节省资源。如果没法送一条消息就要创建链路，发起握手认证，关闭链路释放资源，会损耗大量的系统资源。长连接只在首次创建时或者链路断链重连时才创建链路，链路创建成功之后服务提供者和消费者会通过业务消息和心跳维系链路，实现多消息复用同一个链路节省资源。

2.远程通信是常态，调用时延是关键指标：服务化之后，本地api调用变成了远程服务调用，大量本地方法演化成了跨进程通信，网络时延称为关键指标之一。相比于一次简单的服务调用，链路的重建通常耗时更多，着就会导致链路层的时延消耗远远大于服务调用本身的损耗，这对于大型的业务系统而言无法接收。

BIO和NIO

jdk1.4之前，基于Java的所有socket通信都采用了同步阻塞模式BIO，BIO简化了上层的应用开发，但是性能和可靠性上存在巨大的瓶颈。  jdk1.4之后出现了非阻塞的NIO。

采用BIO通信模型的服务器，通常由一个独立的Acceptor线程负责监听客户端的连接，它接收到客户端连接请求之后为每个客户创建一个新的线程进行链路处理，处理之后通过输出流返回应答给客户端，线程销毁。缺乏弹性的伸缩能力，当客户端并发访问量增加后，系统的性能将急剧下降，随着并发量的增大，系统会发生线程堆栈溢出，创建新线程失败等问题，最终进程宕机或僵死，不能对外提供服务。

 总结：低负载，低并发的应用程序可以选择同步阻塞I/O以降低编程复杂度，但对于构建高性能，低时延，支持大并发的应用系统，需要使用NIO非阻塞模式进行开发。

自主研发还是选择开源的NIO框架：直接使用JavaNIO类库并不好[原因如下]：

1.NIO的类库和API繁杂，使用麻烦，需要熟练掌握Selector,ServerSocketChannel,SocketChannel,ByteBuffer等。

2.需要具备其他额外技能做铺垫，如Java多线程编程。因为NIO编程涉及到Reactor模式，必须对多线程和网络编程非常熟悉，才可以写出高质量的NIO程序。

3.可靠性能力补齐，工作量和难度都非常大。如客户端面临断链重连，网络闪断，半包读写，失败缓存，网络拥塞等，NIO编程的特点是功能开发相对容易，但是可靠性能力补齐的工作量和难度都非常大。

4.JDKNIO的epollbug,会导致selector空轮询，最终导致CPU 100%.

Netty是最成熟的NIO框架，优势：

1.API使用简单，开发门槛低。

2.功能强大，预置了多种编码解码功能，支持多种主流协议

3.定制能力强，可以通过ChannelHandler对通信框架灵活殴打扩展。

4.性能高，比同类型的NIO框架对比，Netty综合性能最优。

5.成熟，稳定，它修复了已经发现的所有JDKNIOBUG，业务开发人员不再为nio的bug烦恼

6.社区活跃，版本迭代周期短，发现的BUG可以被及时修复，同时，更多的功能会加入。

7.经历了大规模的商业应用考验，质量得到验证。

服务端设计三大原则：

1.服务端只提供上层的API，不和任何具体协议绑定

2.服务端提供给用户的API尽量屏蔽底层的通信细节，防止底层的变更引起上层级联变动。

3.服务端功能不要求非常全面，重点在可扩展性。

基于Netty开发通信框架服务端，需要掌握：

1.用于接收客户端连接的线程池：通常被称为bossGroup,它的构造方法于处理I/O读写的线程池相同，bossGroup的线程数建议为1，因为它仅负责接收客户端的连接，不做复杂的逻辑处理，为了尽可能少的占用资源，取值越小越好。

2.TCP参数设置：建议在API层面开发TCP参数设置，为一些特殊的私有协议预留扩展点，对于大多数的开发者，使用默认值就好。

3.编解码框架的定制：通信框架封装Netty的MessageToByteEncoder和LengthFieldBasedFrameDecoder，提供统一，通用的编解码接口或者抽象类，由用户实现编解码接口，实现编解码的灵活定制。

《第四章：序列化和反序列化》

通常我们将序列化叫做编码Encode,它将对象序列化为字节数组，用于网络传输，数据持久化或者其他用途。反序列化称为解码deserialization,decode,把网络，磁盘等读取的字节数组还原成原始对象，以便后续业务逻辑的操作。

进行远程跨进程服务调用时（RPC）,需要使用特定的序列化技术，对需要进行网络传输的对象做编码或解码，以便完成远程调用。

序列化于通信框架不是强耦合的关系，通信框架提供的编码框架可以非常方便的支持用户通过扩展实现自定义的序列化格式。用户也可以在应用程序以及其他位置实现对象的序列化和反序列化，通信框架的编解码接口作为可选插件，并不强调用户一定要在通信框架内部实现消息的序列化和反序列化。

序列化和通信协议是解耦的，同一种通信协议可能由多种序列化方式承载，同一种序列化方式也可以用在不同协议里。如HTTP协议，承载消息体可以是XML,JSON等文本类协议，也可以是图片附件等二进制流媒体协议。

序列化/反序列化框架需要具备特点：

1.默认支持多种常用的序列化/反序列化方式，文本类如XML/JSON等，二进制如PB/thrift等。

2.序列化框架可扩展，用户可以非常灵活，方便的扩展其他序列化方式。

总结：原则上，支持的数据结构种类越多越好，毕竟分布式服务框架面向的是不同业务领域，需要兼顾各种业务场景。如fastjson对泛型支持不好.

java默认提供的序列化机制，实现java.io.Serializable接口并生成序列化ID，这个类就能够通过java.io.ObjectInput和java.io.ObjectOutput序列化和反序列化。但它的最大缺点就是无法支持跨语言。而MessagePack,PB,Thrift,avro都支持多语言。PB前向兼容性好，不必破坏已经部署的，依赖老数据格式的程序就可以对数据结构进行升级。

序列化和反序列化的性能主要由三个指标：

1.序列化后的码流大小

2.序列化和反序列化的速度。

3.资源占用，主要是CPU和对内存。

总结：Protobuf的性能全面占优，分布式服务框架在面向不同领域应用时，需求也不同。如大型网站内部的分布式服务框架的特点就是组网规模大，高并发，海量的小消息通信，以内部服务调用为主，此类场景就比较适合使用高性能的protobuf作为序列化框架。对于企业内部IT系统，服务框架序列化可以选择JSON/XML等文本类数据格式，可读性好。

扩展性设计：利用netty提供的编解码框架，可以非常快速的实现序列化和反序列化框架的扩展，Netty内置了丰富的序列化和反序列化功能类库，用户可以直接使用，避免二次开发。

《第五章：协议栈》

不同服务在性能上适用不同协议进行传输。比如对接异构第三方服务时，通常会选择HTTP/RestFul等共有协议，对于内部不同模块之间的服务调用，往往会选择性能更好的二进制私有协议。

webservice，http等公有协议缺少服务描述文件，服务注册中心和服务订阅发布机制，不太适合作为SOA服务化的标准协议。分布式服务框架主要是为了解决内部服务化之后业务接口跨进程通信问题，吞吐率，时延等性能指标是关键。在性能方面，私有协议往往可以根据业务的具体需求进行针对性优化。

webservice公有协议，性能存在问题：

1.SOAP消息适用XML进行序列化，相比于PB等二进制序列化框架，性能上低一大截。

2.SOAP通常由HTTP协议承载，HTTP1.0/1.1不支持双向全双工通信，而且一般使用短链接通信，性能上较差。

如果没有特殊需求，分布式服务框架默认使用性能更好，扩展性更好的私有协议（二进制）进行通信。对于部分特殊需要于外部对接的服务。可以考虑引入HTTP/Restful等公有协议。

私有协议栈承载了业务内部各模块之间的消息交互和服务调用，主要功能：

1.定义了私有协议的通信模型和消息定义

2.支持服务提供者和消费者采用点对点长连接通信

3.基于javanio通信框架，提供高性能的异步通信能力。

4.提供可扩展的编解码框架，支持多种序列化格式。

5.握手和安全认证机制。

6.链路的高可靠性。

协议消息定义：

通常协议栈的消息模型分为两部分：消息头和消息体。消息头存放协议公共字段和用户扩展字段，消息体用于承载消息内容。以HTTP为例，请求消息头允许客户端向服务器端传递请求的附加消息以及客户端自身的信息，常用的消息头关键字有Accept,Authorization,Host等。

链路创建：考虑到安全，链路建立需要通过基于IP地址或号段的黑白名单安全认证机制，或者通过密钥对用户名和密码+数字签证进行安全认证。

链路关闭：由于采用长连接通信，在正常的业务运行期间，双方通过心跳和业务消息维持链路，任何一方都不需要主动关闭连接。但是，以下需要关闭：

1.当对方宕机或者重启时，会主动关闭连接，另一方读取到操作系统的通知信号，得知对方REST链路，需要关闭连接，释放自身的句柄等资源。由于采用TCP全双工通信，通信双方都需要关闭连接，释放资源。

2.消息读写过程中，发生了I/O异常，需要主动关闭连接

3.心跳消息读写过程中，发生了I/O异常，需要主动关闭连接

4.心跳超时，需要主动关闭连接

5.发生编码异常等不可恢复错误时，需要主动关闭连接。

客户端重连机制：客户端通过链路关闭监听器监听链路状态，如果链路中断，等待Interval时间后，由客户端发起重连操作，如果重连失败，会间隔时间后再次发起重连，直到成功。[有时间间隔，不是失败后就立即重连；客户端会对重连次数做限制，防止无限制重连下去无谓的损耗资源]

安全性设计：

为了保证整个集群环境下的安全，内部长连接采用基于IP地址的安全认证机制，服务端会握手请求消息的IP地址进行合法性校验：如果在白名单内则通过，反之，拒绝对方连接。如果需要将服务开放给第三方非信任域的消费者，则采用密钥和AES加密的用户名+密码认证机制，也可以采用SSL/TSL安全传输。

《第六章：服务路由》

基于服务注册中心的订阅发布：在分布式服务框架中，服务注册中心用于存储服务提供者地址信息，服务发布相关的属性信息，消费者通过主动查询和被动通知的方式获取服务提供者的地址信息。不需要硬编码，这就是透明化路由，工作原理就是基于服务注册中心的订阅发布机制。

服务消费者和服务提供者通过注册中心提供的SDK与注册中心建立链路，服务提供者将需要发布的服务地址信息和属性列表写入注册中心。服务消费者根据本地引用的接口名等信息，从服务注册中心获取服务提供者列表，缓存到本地。提供者如果新增，修改，删除等服务，注册中心检测到服务提供者列表变更后，将主动推送给服务消费者，消费者动态刷新本地缓存的服务提供者地址。

负载均衡：

1.采用随机算法进行负载均衡，通常在对等集群组网中，随机路由算法消息分发比较均匀。缺点有：

  1.在一个截面上碰撞的概率比较高。

  2.非对等集群组网，或硬件配置差异较大，会导致个节点负载不均衡。

2.轮询：按公约后的权重设置轮询比率，到达边界后，继续绕接。缺点：存在曼的提供者累计请求问题。

3.服务调用时延：保证处理强的服务提供者接收到更多的消息，通过动态自动权重调整消除服务调用时延的振荡范围，使所有服务提供者服务调用时延接近平均值，实现负载均衡。

4.一致性哈希：相同参数的请求总是发到同一个服务提供者，当某一台提供者宕机，原本发往该提供者的请求，基于虚拟节点，平摊到其他提供者，不会引起剧烈变动。

5.粘滞连接。

条件路由规则：

1.通过IP条件表达式进行黑白名单访问控制：consumerIP!=192.168.1.1

2.流量引导，只暴露部分服务提供者，防止整个集群都被冲垮，导致其他服务也不可用：providerIP=192.168.3*

3.读写分离：method=find*,list*,get*,query*=>providerIP=192.168.1.*

4.前后台分离：app=web*=>providerIP=192.168.1.*,app=java*=>prodiverIP=192.168.2.*

5.灰度发布，将web前台应用路由到新的服务版本上：app=web*=>providerIP=192.168.1.*

自定义路由的主要应用场景：手机号，终端类型等。

《第七章：集群容错》

通信链路故障：消费者和服务提供者之间的链路（一般为长链接），可能导致原因：

1.通信过程中，对方突然宕机导致链路中断

2.通信过程中，对方因为解码失败等原因Rest掉连接，导致链路中断

3.通信过程中，消费者writesocketChannel发生IOException导致链路中断

4.通信过程中，消费者readsocketChannel发生IOException 导致链路中断

5.通信双方因为心跳超时，主动closesocketChannel,导致链路中断

6.通信过程中,网络发生闪断故障， 导致链路中断

7.通信过程中，交换机异常导致链路中断

8.通信过程中，消费者或提供者因为长时间FULLGC导致链路中断

服务端超时：当服务端无法在指定的时间内返回应答给客户端就会超时，原因可能是：

1.服务端I/O线程没有及时从网路中读取客户端请求信息，导致该问题的原因通常是I/O线程被意外阻塞或执行长周期操作。

2.服务端业务处理缓慢，或长时间阻塞，如查询数据库，由于没有索引导致全表查询，耗时较长。

3.服务端发生长时间FullGC,导致所有业务线程暂停运行，无法及时返回应答给客户端。

服务端调用失败：原因可能是：

1.服务端解码失败，会返回消息解码失败异常

2.服务端发生动态流程，返回流程异常

3.服务端消息队列积压率超过最大阈值，返回系统拥塞异常

4.访问权限校验失败，返回权限相关异常

5.违反SLA策略，返回SLA控制相关异常

6.其他系统异常

容错策略:

1.失败自动切换（failover）,当服务RPC调用异常时，重新选址，查找下一个可用的服务提供者。

 应用场景：1.读操作，因为通常时幂等性的

         2.幂等性服务，保证调用1次和多次效果一样

2.失败通知（failback）:消费者需要能够获取到服务调用失败的具体信息，通过对失败错误码等异常信息的判断，决定后续的执行策略。

3.失败缓存（failCache）:失败自动恢复。

4.快速失败（failfast）:业务高峰时，对于一些非核心的服务，希望只调用一次，失败也不重试，为重要的核心服务节约宝贵的运行资源。[直接忽略异常，记录异常日志即可]。

《第八章：服务调用》

分布式框架中，引入NIO带来的好处是很明显的：

 	同步阻塞I/O(BIO)	伪异步I/O	非阻塞I/O(nio)	异步I/O(AIO)
客户端个数：I/O线程	1:1	M:N(其中M可以>N)	M:1(1个I/O线程处理多个客户端连接)	M:0(不需要启动额外的I/O线程，被动回调)
I/O类型（阻塞）	阻塞I/O	阻塞I/O	非阻塞I/O	非阻塞I/O
I/O类型（同步）	同步I/O	同步I/O	同步I/O(I/O多路复用)	异步I/O
API使用难度	简单	简单	非常复杂	复杂
调试难度	简单	简单	复杂	复杂
可靠性	非常差	差	高	高
总结引入NIO的优点：

1.所有的I/O操作都是非阻塞的，避免有限的I/O线程因为网络，对方处理慢等原因被阻塞。

2.多路复用的Reactor线程模型：基于Linux的epoll和Selector,一个I/O线程可以并行处理成百上千条链路，解决了传统同步I/O通信线程膨胀的问题。NIO只解决了通信层面的异步问题，跟服务调用的异步没有必然关系，也就是说，即便采用了传统的BIO通信，依然可以实现异步服务调用，只不过通信效率和可靠性比较差而已。

异步服务调用相比于同步服务调用有两个优点：

1.化串行为并行，提升服务调用效率，减少业务线程阻塞时间

2.化同步为异步，避免业务线程阻塞。

并行服务调用的目标主要有两个：

1.降低业务E2E时延

2.提升整个系统的吞吐量

解决串行调用效率低的问题，有两个解决方案：

1.异步服务调用

2.并行服务调用

泛化调用：泛化引用/泛化实现。

泛化引用主要用于客户端没有API接口及数据模型的场景，参数及返回值中的所有POJO均用Map表示，通常用于框架集成，比如实现一个通用的服务测试框架。

泛化实现主要用于服务端没有API接口及数据模型的场景，参数及返回值中的所有POJO均用Map表示，通常用于框架集成，比如实现一个通用的远程服务Mock框架。

《第九章：服务注册中心》

如何有效的管理服务订阅/发布，避免硬编码地址信息是分布式服务框架需要解决的一个问题。通过将服务统一管理起来，可以有效地优化内部应用对服务发布/使用的流程和管理，服务注册中心就是专门用来管理服务订阅/发布的配置管理节点。

服务注册中心：服务注册中心是分布式服务框架的目录服务器，相比于传统的目录服务器，它有如下几个特点：

1.高HA:支持数据持久化，支持集群

2.数据一致性问题：集群中所有的客户端应该看到同一份数据，不能出现读或者写数据不一致。

3.数据变更主动推送：当注册中心的数据发生变更时（增加，删除，修改）需要能够及时将变化的数据通知给客户端。

关键功能特性设计：当服务越来越多，服务URL配置管理变得困难，F5等硬件负载均衡器的单点压力越来越大。此时需要一个服务注册中心，动态的注册和发现服务，使服务的地址透明。

微服务调用原理：

1.服务提供者在启动时，根据服务发布文件中配置的服务发布信息向注册中心注册自己提供的服务

2.服务消费者在启动时，根据消费者配置文件中配置的服务消费信息向注册中心订阅自己所需要的服务，消费者刷新本地缓存的路由表

3.注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心主动推送变更数据给消费者，消费者刷新本地缓存的路由表

4.服务消费者从本地缓存的服务提供者地址列表中，基于负载均衡算法选择一台服务提供者进行调用。

提供CRUD接口：客户端连接服务注册中心后，需要能够对服务注册中心的数据进行操作，通常需要用到如下几种操作：

1.查询接口：查询系统当前发布的服务信息和订阅的消费者信息

2.修改接口：修改已经发布的服务属性或者消费者属性，通常用于运行态的服务治理。

3.新增接口：发布或者订阅新的服务

4.删除接口：去注册已经发布的服务，或者消费者取消订阅关系。

安全加固：服务注册中心需要进行安全加固，安全加固主要设计两部分：

1.链路的安全性

2.数据的安全性

链路的安全性指的是服务注册中心对客户端连接进行安全认证，认证策略非常多，最简单的就是基于IP地址的黑名单校验，更加复杂的有基于用户名+密码的认证，或者基于密钥+数字认证。认证失败，则关闭链路，拒绝客户端连接。

数据的安全性主要针对服务注册中心的数据进行权限控制：

1.非授权客户端既不能读取也不能写入数据

2.普通运维人员只能读取数据，不能修改数据

3.管理员既可以读取也可以修改数据

4.不同的服务目录可以设置不同的访问权限，例如消费者只能查看它所在机房的服务。

订阅发布机制：服务注册中心需要支持服务的订阅发布，对于服务提供者，可以根据服务名等信息动态发布服务；对于消费者，可以根据订阅关系主动获得服务发布者的地址信息等。

订阅发布机制还有一个比较重要的机制就是对变化监听和主动推送能力：

1.消费者可以监听一个或多个服务目录，当目录名称，内容发生变更变更时，消费者可以实时的获得变更的数据或者变更后的结果。

2.服务提供者可以发布一个或多个服务，动态修改服务名称，服务内容等，可以主动将修改后的数据或者修改后的结果推送给所有监听此服务目录的消费者。

3.订阅发布机制具有如下几个优点：

1.透明化路由：服务提供者和消费者相互解耦，服务提供者位置透明，消费者不需要再硬编码服务提供者地址。

2.服务健康状态检测：服务注册中心可以实时检测发布服务的质量，如果服务提供者宕机，由服务注册中心实时通知消费者。

3.弹性伸缩能力（动态发现）：应用在云端部署之后，由于VM资源占用率过高，动态伸展出一个新的服务提供者，服务注册中心会将新的服务提供者地址信息推送给消费者，消费者刷新本地路由表之后可以访问新的服务提供者，实现服务的弹性伸缩。

可靠性：服务注册中心需要支持对等集群，任意一台宕机后，服务都能自动切换到其他正常的服务注册中心。如果服务注册中心全部宕机，只影响新的服务注册，已发布服务的下线，不影响服务的正常运行和调用，消费者可以依靠本地缓存的服务路由表进行路由。服务提供者的健康状态检测也由服务注册中心负责检测。服务注册中心通过长连接心跳检测服务提供者的存在。服务提供者宕机，注册中心将立即推送服务下线事件通知消费者，消费者下线的服务提供者地址从缓存的路由表删除，新接入的消息将不再路由到故障节点，实现实时故障隔离。

基于Zookeeper的服务注册统一设计：统一命名服务，状态同步服务，集群管理，分布式应用统一配置等。

服务健康状态：基于zookeeper客户端和服务端的长连接和会话超时控制机制，可以非常方便的实现服务健康状态检测。在zookeeper中，客户端和服务端建立连接后，会话随之建立，生产一个全局唯一sessionID。服务器端和客户端之间维持的是一个长连接，在session_timeout周期内，服务器会检测与客户端的链路是否正常。正常情况下，session会一直有效，并且ZK集群所有机器上都保存这个session信息。在出现网络或者其他问题的情况下（客户端宕机，网络闪断），如果客户端与之前连接的zookeeperserver断链了，此时客户端会主动在地址列表中选择新的地址进行连接。

如果ZK客户端宕机，或者网络出现故障，超过了session_timeout后服务端仍然没有收到客户端的心跳消息，服务器认为这个session已经结束了。ZK中，很多数据和状态都是和会话绑定的，一旦会话失效，那么ZK就开始清除和这个会话有关的信息，包括这个会话创建的临时节点和注册的所有watcher。

对等集群防止单点故障：

zookeeper集群通常由2N+1台server组成，每台Server都直到彼此的存在，每台server都维护内存状态镜像以及持久化存储的事务日志和快照，对于2N+1台server，只要有n+1台server可用，整个集群就保持可用。

系统启动时，集群中的server会选举出一台server为leader,其他的就作为follower，接着由follower来服务client的请求，对于不改变系统一致性状态的读操作，由follower的本地内存数据库直接给client返回结果；对于会改变系统状态的更新操作，则交由leader进行提议投票，超过半数通过后返回结果给client。zookeeper集群管理的核心是源自广播，这个机制保证了各个server之间的数据同步，实现这个机制的协议叫做zab协议。Zab协议有两种模式，他们分别为恢复模式和广播模式。当服务启动或者在leader崩溃后，zab就进入了恢复模式，当leader被选举出来，且大多数server完成了和leader的状态同步后，恢复模式就结束了。状态同步保证了leader和server具有相同的系统状态。

一旦leader已经和多数的follower进行了状态同步后，她就可以开始广播消息了，即进入广播状态。此时当一台server加入zookeeper服务中时，它会在恢复模式下启动，发现leader并和leader进行状态同步。待到同步结束，它也参与消息广播。zookeeper服务一直维持在广播状态，直到leader崩溃了和leader失去了大部分的follower支持。

变更通知机制：服务提供者将服务注册信息保存在zookeeper的某个目录节点上，消费者监控服务配置信息状态，一旦配置信息发生变化。

《第十章：服务发布和引用》

服务提供者需要支持通过配置，注解，API调用等方式，把本地接口发布成远程服务；对于消费者，可以通过对等的方式引用远程服务提供者，实现服务的发布和引用。

服务发布的几种方式：

通常存在三种服务发布方式：

1.XML配置化方式

2.注解方式

3.API调用方式

不同服务发布方式对比
服务发布方式	优点	缺点
XML配置化	
1.服务框架对业务代码零侵入

2.扩展和修改方便           3.修改及配置不需要重新编译代码

无
注解	
1.对业务代码低侵入

2.扩展和修改方便

修改配置需要重新编译代码
API调用	无	
1.对业务代码侵入性较强

2.容易和某种具体的服务框架绑定

3.修改之后需要重新编译

采用XML配置化方式：
<beanid="echoService"class="edu.neu.EServiceImpl>
<xxx:serviceinterface="edu.neu.EService"ref="EService">

采用注解方式发布服务的代码方式：
@Service(name="EService",version="1.0.0",group="Domain")
publicinterfaceEService{
 @Method(timeout=3000,retry=1,executeLimit=10,mock=true) 
 Stringecho(StringpingMsg);
}

采用API调用方式发布服务的代码方式：
EServiceechoService=newEServiceImpl();
ServiceConfigservice=newServiceConfig();
service.setRegistry(registry);
service.setProtocol(protocol);
service.setRef(EService);
service.setName("EService");
service.setVersion("1.0.0");
service.setGroup("Domain");
service.export();

服务发布成指定协议：根据服务配置的属性信息，将服务发布成指定协议[同一个服务允许发布成多种协议的哦]

采用XML配置化方式：
<beanid="echoService"class="edu.neu.EServiceImpl>
<xxx:serviceinterface="edu.neu.EService"ref="EService"，protocol="HTTP,thrift"/>

服务提供者信息注册：将服务按照约定协议发布后，需要将服务发布信息注册到注册中心，服务注册的目的有两个：

1.供消费者订阅服务地址信息进行服务路由。

2.基于服务注册中心的统一服务治理。

同步还是异步发布服务：

对于大型应用系统，发布的服务比较多，系统启动时间会比较长，一个优化思路就是采用异步发布服务加速系统启动。但是这会带来，可能系统已经启动成功，但是还是部分服务没有发布，也就是说系统已经成功，但是部分服务还没完成初始化。

警惕网络风暴：在大规模集群系统中，服务注册中心可能管理数十万条的服务注册信息以及上万个服务提供者和消费者。如果服务注册管理了大量经常变更的信息，就会发生频繁的变更通知；而这种海量的变更通知可能会挤占服务注册中心的网络带宽，严重时还会导致网络风暴。

设计时需要考虑如下几个要素：

1.哪些信息需要注册到服务注册中心，需要甄别。

2.服务注册中心能够管理的服务上限。

3.服务注册中心的网络带宽规划。

4.服务注册的磁盘空间规划。

5.服务注册中心的性能。

配置扩展：无论是服务提供者还是消费者，功能均会不断增加；而通过配置扩展的方式增加新功能，可以保证业务的前向兼容，同时保持架构的稳定性。

总结：一个好的分布式服务框架对业务代码的侵入要足够低，例如通过XML配置化的方式将普通的Java接口成远程服务；消费者通过配置化的方式引用服务提供者的接口。基于接口编程，服务框架底层无论如何变更都不会影响上层应用，这就真正实现了业务和平台解耦。

《第十一章：服务灰度发布》

灰度发布是指在黑于白之间，能够平滑过滤的一种发布方式。ABtest就是一种灰度发布方式:让一部分用户继续用A,一部分用户开始用B；如果用户对B没有什么反对意见，那么逐步扩大范围，把所有用户都迁移到B上面来。灰度发布可以保证整体系统的稳定，在初始灰度的时候就可以发现，调整问题，以保证其影响度。

服务灰度发布的主要作用如下：

1.解决服务升级不兼容问题。

2.及早获得用的用户的意见反馈，完善产品功能，提升服务质量。

3.缩小服务升级所影响的用户范围，降低升级风险。

4.让用户及早参与产品测试，加强用户互动。

灰色环境准备：需要对灰度环境进行划分，隔离和准备。

1	系统运维人员通过管理员账号登陆灰度发布Portal或者进入服务治理的灰度发布界面
2.	在生产环境中年圈定本轮灰度发布的范围，通常是一个应用集群，包括前后台服务，当然也可能是单个服务
3.	将选择的服务灰度发布范围信息保存到服务注册中心，用于后续的规则下发和灰度升级历史记录查询等
4.	通知灰度升级范围内的服务实例下线，通常会采用优雅停机的方式让待升级的服务下线，保证升级不中断业务
5.	应用进程接收到优雅停机指令后，将本进程内缓存的消息处理完，然后优雅退出
6.	从软件仓库选择需要升级的服务安装镜像包，用于灰度环境的版本升级
7.	将升级包批量上传到灰度环境中，把原来的业务软件包做本地备份后，升级服务版本
8.	灰度环境升级部署成功之后，返回灰色环境部署成功消息给灰度发布管理控制台，然后进行后续的灰度发布操作。
灰度规则设置：

1.按照接入门户类型分类：网上营业厅，手机客户端，营业厅实体店，自助业务办理终端

2.按照终端类型分类：安卓，IOS,Windows,phone等。

3.按照区域进行划分，例如东北，华北，华中等。

《第十二章：参数传递》

服务消费者和提供者之间进行通信时，除了接口定义的请求参数，往往还需要携带一些额外参数，例如消息提供者的IP地址，消息调用连的跟踪ID等；这些参数不能通过业务接口来进行传递，需要底层的分布式服务框架支持这种参数传递方式。

内部传参主要指服务提供者或者消费者接口内部业务上下文信息的传递，主要包含：

1.业务内部参数传递。

2.服务框架和业务之间的参数传递。

业务内部参数传递：无论时提供者还是消费者，他们都需要调用本地API对业务逻辑进行编排。API调用将涉及参数传递，比较常用的业务流程编排有三种：

1.	硬编码，在业务逻辑中进行API调用，参数通过API接口进行引用传参
2.	业务编排引擎对业务流程进行编排，参数往往通过抽象的编排上下文进行传递
3.	通过专业的BPM流程引擎进行业务逻辑编排，参数通过流程传递。
1.硬编码通常会直接通过方法参数进行参数传递，因为对于本地方法而言，不需要有严格的契约对参数进行约束，内部修改和代码重构也非常方便和随意

2.通过线程上下文进行参数传递。通常情况下业务逻辑处理过程中很少发生线程切换，因此通过线程上下文进行隐式传参可以不和某个具体方法接口耦合，对业务接口没有侵入，使用起来非常方便。如spring的资源和事务线程绑定机制，利用的就是JDK提供的线程上下文。使用线程上下文传参是一种隐式传参。它的好处就是不需要再通过参数引用的方式进行参数传递，只要线程不发生切换，可以在任何地方设置，更新和获取上下文信息，大大提高了业务的开发效率。

3.业务编排引擎实际上就是轻量级的BPM流程引擎，它往往基于指责连模式实现，业务流程被抽象成handle,由指责连编排引擎服务对业务流程进行编排。

publicinterfaceIHandler{voidexecute(MessageContextcontext)throwsException;}

业务的各个处理流程被抽象成各个handler,上下文统一包装成MessageContext对象，业务参数通过MessageContext在不同的Handler中被传递处理。采用链式编排的好处是业务修改起来非常方便，编程模型也比较统一，代码更容易管理和维护。

3.BPM流程引擎。根据BPMN的规范，流程引擎通过流程上下文进行参数传递，用户可以在流程编排界面声明流程级参数和全局参数，流程引擎通过流程上下文进行参数传递，它的使用方式和线程上下文类似，是一种更高级的接口封装形式。

服务框架内部参数传递：服务框架内部由多个模块组成，模块之间的调用通常会发生线程切换；另外，当服务框架通过反射调用服务接口实现类时，也需要向服务代码传递一些额外的参数。通常框架将数据报文反序列化成业务请求对象之后，需要将消息封装成Task,丢到后面的业务线程池中执行，此时会发生线程切换。利用Map<String,Object>扩展参数。

外部传参：外部传参主要用于服务消费者和提供者之间进行参数传递，主要用途包括两个:

1.服务框架自身的参数传递，例如分布式事务中的事务上下文信息传递。

2.业务之间的参数传递，例如业务调用链ID的传递，用于唯一标识某个完整业务流程。

通信协议支持：消费者自定义参数传递到服务端，需要有一个载体，它就是通信协议。一个设计良好的协议，往往支持用户自定义扩展消息头，在协议消息头中，可以预留一个Map<String,byte[]>类型的字段，用于服务框架或者用户自定义参数扩展。

防止参数互相覆盖：

由于使用的是Map或者线程变量，因此需要防止参数互相覆盖：

1.服务框架系统参数和业务参数互相覆盖

2.业务之间的参数覆盖

参数生命周期管理：无论使用Map还是线程变量，都需要对参数的生命周期进行管理，否则容易导致内存泄漏。解决问题的最好办法就是平台API多提供一个删除模式的参数，允许用户手动删除，如果用户不指定就使用自动删除模式，通过显示的参数定义将内存管理作为契约强制约束使用者进行设置。

《第十三章：服务多版本》

服务多版本管理对象包括服务提供者和消费者。

1.服务提供者：发布服务的时候，支持指定服务的版本号

2.服务消费者：消费服务的时候，支持指定引用的服务版本号或者版本范围。

服务的版本号信息并不是仅供人工阅读的，“版本”在分布式服务框架中是一个受系统管理的信息，维护一个服务的不同版本也是分布式服务框架支持服务在线升级的重要特性。当一个消费者依赖某个服务提供者时，通常需要指明它依赖服务的版本号信息。

完整的版本号：主版本号(Major)+副板本号(Minor)+微版本号(Micro)构成。

主版本号(Major)	表示重大特性或者功能变更，接口或者功能可能会不兼容
副板本号(Minor)	发生了少部分功能变更，或者新增了一些功能
微版本号(Micro)	主要用于BUG修复，对应于常见的SP补丁包
服务框架中引入版本范围的原因如下：

1.消费者关心的是某个新特性从哪个服务版本中开始提供，它并不关心服务提供者的版本演进以及具体的版本号。

2.消费者想使用当前环境中服务的最新版本，但是并不清楚具体的版本号，希望自动适配最新的服务版本。[如不指定，默认将查找0.0.0  如果找不到就抛出指定的RPC异常。]

基于版本号的服务路由：服务提供者将服务注册到注册中心时，将服务名+服务版本号+服务分组作为路由关键信息存放到注册中心，服务消费者在发起服务调用时，除了携带服务名，方法名和参数列表外，还要懈怠要消费的服务版本信息，由路由接口服务服务版本过滤。

《第十四章：流量控制》

当资源成为瓶颈时，服务框架需要对消费者做限流，启动流控保护机制。流控有多种策略，比较常用的有：针对访问速率的静态流控，针对资源占用的动态流控，针对消费者并发连接数的连接控制和针对并行访问数的并发控制。

静态流控：主要针对客户端访问速率进行控制，它通常根据服务质量等级协议（SLA）中约定的QPS做全量流控，例如订单服务的静态流控阈值为100QPS,则无论集群有多少个订单服务实例，它们总的处理速率之和不能超过100QPS.

传统静态流控设计方案：传统的静态流控设计采用安装预分配方案，在软件安装时，根据集群服务节点个数和静态流控阈值，计算每个服务节点分摊的QPS阈值，系统运行时，各个服务节点按照自己分配的阈值进行流控，对于超出流控阈值的请求则拒绝访问。

服务框架启动时，将本节点的静态流控阈值加载到内存中，服务框架通过Handler拦截器在服务调用前做拦截计数，当计数器在指定周期T到达QPS上限时，启动流控，拒绝新的请求消息接入。

有两点需要注意：

1.服务实例通常由多线程执行，因此计数时需要考虑线程并发安全，可以使用Atomic原子类进行原子操作。

2.到达流控阈值之后拒绝新的请求消息接入，不能拒绝后续的应答消息，否则这会导致客户端超时或者触发FailOver,增加服务端的负载。

传统方案的缺点：静态分配的最大缺点就是忽略了服务实例的动态变化。

1.云端服务的弹性伸缩特性使服务节点数处于动态变化过程中，与分配方案行不通。

2.服务节点宕机，或者有新的服务节点动态加入，导致服务节点数发生变化，静态分配的QPS需要实时动态调整，否则会导致流控不准。

分布式服务框架的一个特点就是服务的动态上下线和自动发现机制，这就决定了在运行期间服务节点数会随着业务量的变化而频繁的变化，在这种场景下静态分配方案显然无法满足需求。当应用和服务迁移到云上之后，Paas平台的一个重要功能就是支持应用和服务的弹性伸缩，在云上，资源都是动态分配和调整的，静态分配阈值方案无法适应服务迁移到云上。

动态配额分配制：由于服务注册中心以流控周期T为单位，动态推送每个节点分配的流控阈值QPS，当服务节点发生变化时，会触发服务注册中心重新计算每个节点的配额，然后进行推送，这样无论是减少还是新增服务节点，都能够在下一个流控周期内被识别和处理，这就解决了传统静态分配方案无法适应节点数动态变化的问题。

结合负载均衡进行静态流控，才能实现更精确的调度和控制。消费者根据各个服务节点的负载情况做加权路由，性能差的路由到的消息更少，由于配额计算也根据负载做了加权调整，最终分配给性能差的节点配额指标也较少，这样既保证了系统的负载均衡，又实现了配额的更合理分配。

动态流控因子：动态流控因子包括系统资源和应用资源两大类，常用的系统资源包括：

1.应用进程所在主机VM的CPU使用率

2.应用进程所在主机VM的内存使用率

常用的应用资源包括：

1.JVM堆内存使用率

2.消息队列积压率

3.会话积压率

并发控制：并发控制针对线程的并发执行数进行控制，他的本质是限制堆某个服务或者服务的方法过度消费，耗用过多的资源而影响其他服务的正常运行。

并发控制有两种形式：

1.针对服务提供者的全局控制

2.针对服务消费者的全局控制

服务端提供者的并发执行数为5，如果超过5，则抛出并行控制异常： 

<beanid="echoService"class="edu.neu.EServiceImpl>
<xxx:serviceinterface="edu.neu.EService"ref="EService"executes="5"/>

或

<beanid="echoService"class="edu.neu.EServiceImpl>
<xxx:serviceinterface="edu.neu.EService"ref="EService">

<xxx:methodname="echo"executes="5"/>

</xxx:service>

服务消费者流控：

<beanclass="edu.neu.EServiceImplinit-method="start">
<xxx:referenceid="EService" interface="edu.neu.EService"actives="5">

或

<beanclass="edu.neu.EServiceImplinit-method="start">
<xxx:referenceid="EService" interface="edu.neu.EService">

<xxx:methodname="echo"actives="5"/>

</xxx:reference>

连接控制：分布式服务框架服务提供者和消费者之间采用长连接私有协议，为了防止因为消费者连接数过多导致服务端负载压力过大，系统需要支持针对连接数进行流控。

服务端连接数流控[限制XXX协议客户端连接数不能超过50]：

<beanclass="edu.neu.EServiceImplinit-method="start">
<xxx:protocolname="xxx"accepts="50"/>

消费者连接数流控：

<beanclass="edu.neu.xxxAction"init-method="start">

<xxx:referenceinterface="edu.nue.EService"connections="50"/>

《第十五章：服务降级》

像秒杀类似的活动，让业务高峰时，为了保证核心服务的SLA，往往需要停掉一些不太重要的业务，比如评论，论坛，粉丝积分等。

另外某些服务因为某种原因不可用，但是流程不能直接失败，需要本地Mock服务端实现，做流程放通。

对一些非核心服务做强制降级，不发起远程服务调用，直接返回空，异常或则和执行特定的本地逻辑，减少自身对公共资源的浪费，把资源释放出来供核心服务使用。

屏蔽降级的三种方式：

1.不发起远程服务调用，直接返回空对象。

2.不发起远程服务调用，直接抛出指定异常。

3.不发起远程服务调用，直接执行本地模拟接口实现类。

容错逻辑主要包含两种：

1.RPC异常：通常指超时异常，消息解码异常，流控异常，系统拥塞保护异常等。

2.Service异常：例如登陆校验失败异常，数据库操作失败异常等。

容错降级和屏蔽降级主要差异：

1.触发条件不同：容错降级时根据服务调用结果，自动匹配的；而屏蔽降级往往时人工根据系统运行情况手工操作触发的。

2.作用不同：容错降级时当服务提供者不可用时，让消费者执行业务放通；屏蔽降级的主要目的时将原属于降级业务的资源调配出来供核心业务使用。

3.调用机制不同：一个发起远程服务调用，一个制作本地调用。

总结：无论屏蔽降级还是容错降级，都支持从消费者或者提供者两个维度去配置，从消费者配置策略更灵活，可以实现差异化降级策略，当然使用起来也更加麻烦。

服务降级策略配置的优先级为：消费者配置策略>服务提供者配置策略，屏蔽降级高于容错降级。

《第十六章：服务优先级调度》

当系统当前资源非常有限时，为了保证高游侠你的服务能够正常运行，保障服务SLA,需要降低一些非核心服务的调度频次，释放部分资源占用，保障系统的整体运行平稳。

服务优先级的调度策略非常多，对于分布式服务框架而言，需要能够支持服务发布时设置优先级策略，并在资源成为瓶颈时，按照用户配置的优先级策略调用执行服务。服务在发布的时候，可以指定服务的优先级，如果用户没有指定，采用默认优先级策略，它的配置如下：

<xxx:serviceinterface="edu.neu.EService"ref="EService"mock="force:executeBean:echoServiceMock"priority="HIGN"/>

服务的优先级可以采用传统的低中高三级配置策略，每个级别的执行比例可以灵活配置，如：

<xxx:priority
<Leveltype="HIGH"value="0.5"/>
<Leveltype="MID"value="0.3"/>
<Leveltype="LOW"value="0.2"/>
</xxx:priority>

服务发布XSD通过扩展priority属性的方式指定优先级，服务提供者将优先级属性注册到服务注册中心并通知消费者，由消费者缓存服务的优先级，根据不同的优先级策略进行调度。

服务优先级调度有多种策略：

1.基于线程调度器的优先级调度策略。
2.基于优先级队列的优先级调度策略。
3.基于加权配置的优先级调度策略。
4.基于服务迁入迁出的优先级策略。
线程调度器方案：设置Thread的setPriority(intnewPriority)接口，线程的优先级取值介于MAX_PRIORITY=10和MIN_PRIORITY=1之间，共10个级别，默认取值为NORM_PRIORITY=5

依赖于线程调度器来实现服务的优先级调度，很有可能是不可移植的。在不同的操作系统上，相同的优先级配置，执行结果却可能存在很大差异，这对于某些精确控制执行比例的服务是不可接受的。无法保证精确性和跨平台移植性。

Java优先级队列：Java的priorityQueue是一个基于优先级堆的无界优先级队列。优先级队列的元素按照其自然顺序进行排序，或者根据构造队列提供的Comparator进行排序，具体取决于所使用的构造方法。优先级队列不允许使用null元素，依靠自然顺序的优先级队列还不允许插入不可比较的对象。

优先级队列的头是按照指定排序方式确定的最小元素，如果多个元素都是最小值，则头是其中一个元素（任意）队列获取操作poll,remove,peek,element访问处于队列头的元素。优先级队列是无界的，但有一个内部容量，控制着用于存储队列元素的数组大小，他通常至少等于队列的大小，随着不断向优先级队列添加元素，其容量会自动增加，无须指定容量增加策略的细节。使用Java优先级队列,服务的优先级调度由JDK负责，由于priorityQueue的优先级调度由优先级算法本身决定，于平台无关，因此具备跨平台和可移植性。

总结：priorityQueue缺点就是如果持续有优先级高的消息需要处理，会导致优先级低的消息得不到及时处理而积压，当积压到一定程度之后，低优先级的消息可能已经超时，即便后续会得到执行机会，由于已经超时也需要丢弃，在此之前，它会一直占用优先级队列的堆内存，同时导致客户端业务线程被挂住等待应答消息直到超时，从资源调度层看，priorityQueue算法并不太适合分布式服务框架。

加权优先级队列：分布式服务框架的服务优先级调度并不是只处理高优先级的消息，而是按照一定比例优先调度高优先级的服务，采用加权优先级队列可以很好的满足这个需求。

《第十九章：可靠性设计》

相对于传统的本地JavaAPI调用，跨进程的分布式服务调用面临的故障风险更高：

1.网络类故障：链路闪断，读写超时等
2.序列化和反序列化失败
3.畸形码流
4.服务端流控和拥塞保护导致的服务调用失败
对于应用而言，分布式服务框架需要具备足够的健壮性，在平台底层能够拦截并向上屏蔽故障，业务只需要配置容错策略，即可实现高可高靠性。

服务状态检测：在分布式服务调用时，某个服务提供者可能已经宕机，如果采用随机路由策略，消息会继续发送给已经宕机的服务提供者，导致消息发送失败。为了保证路由的正确性，消费者需要能够实时获取服务提供者的状态，当某个服务提供者不可用时，将它从缓存的路由表中删除掉，不再向其发送消息，直到对方恢复正常。

基于服务注册中心状态检测：使用服务注册中心堆服务提供者进行状态检测，当检测到服务提供者不可用时，会将故障的服务信息广播到集群所有节点，消费者接收到服务故障通知消息之后，根据故障信息中的服务名称，IP地址等信息，对故障节点进行隔离。zookeeper服务端利用于客户端之间的长连接会话做心跳检测，当连续N次都没有接收到客户端的心跳应答时，认为对方不可用，将长连接会话删除，同时向其他监听该会话节点的监听者推送超时节点被删除的详细信息，消费者根据超时的节点信息，获取服务名称，版本号，分组信息，IP地址和端口等，利用这些信息更新服务提供者路由缓存表，将故障服务节点隔离，不再向其发送消息。

链路有效性状态检测机制：分布式服务框架的服务提供者和消费者之间默认采用长连接，并且通过双向心跳检测保障链路的可靠性。【服务注册中心检测+服务提供者和消费者之间的链路有效性检测双重检测来保障系统的可靠性】

当消费者通过双向心跳检测发现链路故障之后，会主动释放连接，并将对应的服务提供者从路由缓存表中删除。当链路恢复之后，重新将恢复的故障服务提供者地址信息加入地址缓存表中。

服务健康度检测：

服务的健康度检测通常需要采集如下性能KPI指标：

1.服务调用时延

2.服务QPS

3.服务调用成功率

4.基础资源使用情况，例如堆内存，CPU使用率等。

服务故障隔离：

1.进程级故障隔离

2.VM级别故障隔离

3.物理机故障隔离

4.机房故障隔离

进程级故障隔离：进程内部，主要通过将服务部署到不同的线程池实现故障隔离。

《第二十一章：服务化最佳实践》

服务化之后，服务提供者和消费者之间采用远程网络通信，增加了额外的性能损耗：

1.客户端需要对消息进行序列化，主要占用CPU计算资源

2.序列化时需要创建二进制数组，耗费JVM堆内存或者堆外内存

3.客户端需要将序列化之后的二进制数组发送给服务端，占用网络带宽资源

4.服务端读取到码流之后，需要将请求数据报反序列化成请求对象，占用CPU计算资源

5.服务端通过反射的方式调用服务提供者实现类，反射本身对性能影响就比较大。

6.服务端将响应结果序列化，占用CPU计算资源。

7.服务端将应答码流发送给客户端，占用网络带宽资源。

8.客户端读取应答码流，反序列化成响应消息，占用CPU资源。

影响RPC框架性能的主要因素有三个：

1.I/O调度模型：同步阻塞I/O(bio),还是异步I/O(nio)

2.序列化框架的选择：文本协议，二进制协议，压缩二进制协议。

3.线程调度模型：串行调度还是并行调度，锁竞争还是无锁化算法。

高性能序列化框架：

1.序列化后的码流大小

2.序列化和反序列化的性能

3.是否支持跨语言

4.并发调用性能表现：稳定性，线性增长，偶现的时延毛刺等。

高性能业务最佳实现：

1.能异步的尽可能使用异步或者并行服务调用，提升服务的吞吐量，有效降低服务调用时延。

2.无论时NIO通信框架的线程池还是后端业务线程池，线程参数的配置必须合理。如果采用JDK默认的线程池，最大线程数建议不超过20个。因为JDK的线程池默认采用N个线程争用1个同步阻塞队列方式，当线程数过大时，会导致激烈的锁竞争，此时性能不仅不提升，反而会下降。

3.尽量减小要传输的码流大小，提升性能。本地调用时，由于在同一块堆内存中访问，参数大小对性能没有任何影响。跨进程通信时传递的是个复杂对象，不要把整个复杂对象都传递过去。

4.设置合适的客户端超时时间，防止业务高峰时期因为服务端响应慢导致业务线程等应答时被阻塞，进而引起后续其他服务的消息在队列中排队，造成故障扩散。

5.对于重要的服务，可以单独部署到独立的服务线程池中，与其他非核心服务做隔离，保障核心服务的高效运行。

6.利用Docker等轻量级OS容器部署服务，对服务做物理资源层隔离，避免虚拟化之后导致的超过20%的性能损耗。

7.设置合理的服务调度优先级，并根据线上性能监控数据做实时调整。

分布式解决方案：

两阶段提交：

阶段一：全局事务管理器向所有事务参与者发送准备请求；事务参与者向全局事务管理器回复自己是否准备就绪。

阶段二：全局事务管理器接收到所有事务参与者的回复之后做判断，如果所有事务参与者都可以提交，则向所有事务提交者发送提交申请，否则就进行回滚。事务参与者根据全局事务管理器的指令进行提交或者回滚操作。

两阶段提交采用的时悲观锁策略，由于各个事务参与者需要等待响应最慢的参与者，因此性能比较差。第一个问题时协议本身的成本：整个协议过程是需要加锁的，比如锁住数据库的某条记录，且需要持久化大量事务状态相关的操作日志。更为麻烦的是，两阶段锁在出现故障时表现出来的脆弱性，比如两阶段锁的致命缺陷：当协调者出现故障，整个事务需要等到协调者回复后才能继续执行，如果协调者出现类似磁盘故障等错误，该事务将被永久遗弃。

MQ解决：在做本地事务之前，先向MQ发送一个prepare消息，然后执行本地事务，本地事务提交成功的化，向MQ发送一个commit消息，否则发送一个rollback消息，取消之前的消息。MQ只会在收到commit确认才会将消息投递出去，所以这样的形式可以保证在一切正常的情况下，本地事务和MQ可以达到一致性。但是分布式调用存在很多异常场景，如网络超时，VM宕机等。假如系统执行了locl_tx()成功之后，还没来得及将commit消息发送给MQ，或者说发送出去由于网络超时等原因，MQ没有收到commit，发生了commit消息丢失，那么MQ就不会把prepare消息投递出去。MQ会根据策略去尝试询问（回调）发消息的系统（CheckCommit）进行检查该消息是否应该投递出去或者丢弃，得到系统的确认之后，MQ会做投递还是丢弃，这样就保证了MQ和发消息的系统的一致性，从而保证了接受消息系统的一致性。

原文：https://blog.csdn.net/qq_35781178/article/details/86430012